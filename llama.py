from langchain.memory import ChatMessageHistory
from langchain_chroma import Chroma
from langchain_ollama import OllamaLLM
from langchain_ollama.embeddings import OllamaEmbeddings

# Inicializar modelo de embeddings y modelo Llama3.2 con el nombre NoneBot
embeddings = OllamaEmbeddings(model="nomic-embed-text")
nonebot = OllamaLLM(model="llama3.2")  # Ahora el modelo se llama NoneBot

# Inicializar memoria para recordar mensajes anteriores
memory = ChatMessageHistory()

# Cargar la base de datos asegurando el nombre de la colecci√≥n correcto
chroma_db = Chroma(
    embedding_function=embeddings,
    persist_directory="./chroma_db",
    collection_name="portafolio_documents",
)

# Verificar si los documentos realmente est√°n indexados
cantidad_documentos = len(chroma_db.get()["ids"])
print(f"Cantidad de documentos en la base de datos: {cantidad_documentos}")

# Mensaje de bienvenida con la identidad de NoneBot
print("\nüí¨ Bienvenido al chat con NoneBot, el asistente personal de Antonio.")
print("Escribe 'salir' para terminar la conversaci√≥n.\n")

# Bucle de conversaci√≥n interactiva
while True:
    # Recibir la pregunta del usuario
    query = input("üó®Ô∏è  Tu pregunta: ")

    # Permitir salir del chat
    if query.lower() == "salir":
        print("üëã ¬°Hasta luego! Gracias por visitar el portafolio de Antonio.")
        break

    # Guardar la interacci√≥n en memoria
    memory.save_context({"input": query}, {"output": ""})

    # Realizar la b√∫squeda en ChromaDB para encontrar contexto relevante
    resultados = chroma_db.similarity_search(query, k=1)

    contexto_base = (
        "Tu nombre es NoneBot y est√°s alojado en el portafolio de Antonio Moreno. "
        "Tu funci√≥n es resolver con precisi√≥n y elegancia las dudas de quienes visitan el portafolio. "
        "Responde de forma directa, con un ingenio afilado y un toque sofisticado, sin perder claridad. "
        "Tus respuestas deben ser breves, precisas y con un toque sarc√°stico cuando sea apropiado. "
        "Utiliza emojis con moderaci√≥n, solo cuando aporten expresividad al mensaje. üéØ "
        "Evita presentarte o agradecer constantemente. No hables en primera persona como si fueras Antonio Moreno. "
        "En todo momento, procura dejar a Antonio en buen lugar, ya que muchas de las personas que acceden al portafolio podr√≠an estar interesadas en contratar sus servicios. "
        "Ofrece informaci√≥n exacta, sin especulaciones ni asumir informaci√≥n personal. "
        "Si la informaci√≥n es insuficiente, dilo con estilo e ingenio. ü§ñ"
    )

    # Construir el prompt incluyendo la memoria y el contexto
    historial = memory.load_memory_variables({})
    memoria_texto = historial.get("history", "")

    if resultados:
        contexto_documento = resultados[0].page_content
        prompt = (
            f"{contexto_base}\n"
            f"Contexto adicional del portafolio: {contexto_documento}\n\n"
            f"Historial de la conversaci√≥n:\n{memoria_texto}\n"
            f"Pregunta: {query}\nRespuesta:"
        )

        # Generar la respuesta usando NoneBot
        respuesta = nonebot.invoke(prompt)
        print(f"ü§ñ NoneBot: {respuesta}\n")

        # Actualizar la memoria con la respuesta generada
        memory.save_context({"input": query}, {"output": respuesta})

    else:
        print("‚ùå No se encontr√≥ informaci√≥n relevante en el portafolio de Antonio.\n")
